---
title: 基于深度卷积神经网路的图像网络分类
tags:
  - 论文总结
---

# 基于深度卷积神经网路的图像网络分类

TCP和UDP：

<img=src="/assets/image/image-20210905201655869.png" />

神经网络：神经网络是一组按层次组成的神经元。每个神经元都是一个数学计算，它接受输入，乘以它的权重，然后通过激活函数将总和传递给其他神经元。神经网络正在学习如何根据前面的例子调整输入的权重来对输入进行分类。

过拟合：过拟合是指为了得到一致假设的而使假设变得过度严格。避免过拟合是分类器设计中的一个核心任务。通常采用增大数据量和测试样本集的方法对分类器性能进行评价。

欠拟合：欠拟合是指模型拟合程度不高，数据距离拟合曲线较远，或指模型没有很好的捕捉到数据特征，不能够很好的拟合数据。

卷积层：卷积神经网络中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法最佳化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。

最大池化：最大池化（max-pooling）即局部接收域中值最大的点。

> 常用的池化方法有最大池化（max-pooling）和均值池化（mean-pooling）。根据相关理论，特征提取的误差主要来自两个方面：
>
> （1）领域大小受限造成的估计值方差增大。
>
> （2）卷积层参数误差造成估计均值的偏移。
>
> 一般来说，mean-pooling能减小第一种误差，更多的保留图像的背景信息，max-pooling能减小第二种误差，更多的保留纹理信息。与mean-pooling近似，在局部意义上，则服从max-pooling的准则。
>
> max-pooling卷积核的大小一般是2X2。非常大的输入量可能需要4X4。但是，选择较大的形状会显著降低信号的尺寸，并可能导致信息过度丢失。通常，不重叠的池化窗口表现最好。

非饱和神经元：

------

全连接层：在整个卷积神经网络中起到“分类器”的作用。如果说卷积层、池化层和激活函数层等操作是将原始数据映射到隐层特征空间的话，全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。在实际使用中，全连接层可由卷积操作实现：对前层是全连接的连接层可以转化为卷积核为1X1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽。

https://www.zhihu.com/question/41037974

------



dropout：

softmax：

非饱和神经元：

